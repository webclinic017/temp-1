{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Logistic Regression using SGD.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"I2S-uFqwSvmg","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","from sklearn.datasets import make_classification"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FUxLkBjISvmr","colab_type":"code","colab":{}},"source":["X, y = make_classification(n_samples=50000, n_features=15, n_informative=10, n_redundant=5,\n","                           n_classes=2, weights=[0.7], class_sep=0.7, random_state=15)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xexp5GYNSvmz","colab_type":"code","outputId":"48e3356f-3756-4945-f6b7-f643b59063b4","colab":{}},"source":["X.shape, y.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((50000, 15), (50000,))"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"54vJVc_KSvm9","colab_type":"text"},"source":[" "]},{"cell_type":"code","metadata":{"id":"9pKAn1-ASvm_","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import train_test_split"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"r97pFTgrSvnE","colab_type":"code","colab":{}},"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=15)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jykLIXZNSvnJ","colab_type":"code","outputId":"2e462e5f-1546-4edf-bcc8-e7a42f9057d7","colab":{}},"source":["X_train.shape, y_train.shape, X_test.shape, y_test.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((37500, 15), (37500,), (12500, 15), (12500,))"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"g0-M6oXASvnO","colab_type":"text"},"source":[" "]},{"cell_type":"code","metadata":{"id":"sShoMeocSvnP","colab_type":"code","colab":{}},"source":["from sklearn import linear_model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gm6wi8L2SvnU","colab_type":"code","outputId":"dccc42b5-e1eb-4e2f-9fa2-07f405d4f761","colab":{}},"source":["# alpha : float\n","# Constant that multiplies the regularization term. \n","\n","# eta0 : double\n","# The initial learning rate for the ‘constant’, ‘invscaling’ or ‘adaptive’ schedules.\n","\n","clf = linear_model.SGDClassifier(eta0=0.0001, alpha=0.0001, loss='log', random_state=15, penalty='l2', tol=1e-3, verbose=2, learning_rate='constant')\n","clf"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n","       early_stopping=False, epsilon=0.1, eta0=0.0001, fit_intercept=True,\n","       l1_ratio=0.15, learning_rate='constant', loss='log', max_iter=None,\n","       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n","       power_t=0.5, random_state=15, shuffle=True, tol=0.001,\n","       validation_fraction=0.1, verbose=2, warm_start=False)"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"Q4WFoxgASvnc","colab_type":"code","outputId":"469de818-0a3e-42e8-bc19-ac6d088b9617","colab":{}},"source":["clf.fit(X=X_train, y=y_train)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["-- Epoch 1\n","Norm: 0.76, NNZs: 15, Bias: -0.314605, T: 37500, Avg. loss: 0.455801\n","Total training time: 0.01 seconds.\n","-- Epoch 2\n","Norm: 0.92, NNZs: 15, Bias: -0.469578, T: 75000, Avg. loss: 0.394737\n","Total training time: 0.02 seconds.\n","-- Epoch 3\n","Norm: 0.98, NNZs: 15, Bias: -0.580452, T: 112500, Avg. loss: 0.385561\n","Total training time: 0.03 seconds.\n","-- Epoch 4\n","Norm: 1.02, NNZs: 15, Bias: -0.660824, T: 150000, Avg. loss: 0.382161\n","Total training time: 0.05 seconds.\n","-- Epoch 5\n","Norm: 1.04, NNZs: 15, Bias: -0.717218, T: 187500, Avg. loss: 0.380474\n","Total training time: 0.06 seconds.\n","-- Epoch 6\n","Norm: 1.06, NNZs: 15, Bias: -0.761816, T: 225000, Avg. loss: 0.379481\n","Total training time: 0.07 seconds.\n","-- Epoch 7\n","Norm: 1.06, NNZs: 15, Bias: -0.793932, T: 262500, Avg. loss: 0.379096\n","Total training time: 0.08 seconds.\n","-- Epoch 8\n","Norm: 1.07, NNZs: 15, Bias: -0.820446, T: 300000, Avg. loss: 0.378826\n","Total training time: 0.09 seconds.\n","-- Epoch 9\n","Norm: 1.07, NNZs: 15, Bias: -0.840093, T: 337500, Avg. loss: 0.378604\n","Total training time: 0.10 seconds.\n","-- Epoch 10\n","Norm: 1.08, NNZs: 15, Bias: -0.850329, T: 375000, Avg. loss: 0.378615\n","Total training time: 0.11 seconds.\n","Convergence after 10 epochs took 0.11 seconds\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n","       early_stopping=False, epsilon=0.1, eta0=0.0001, fit_intercept=True,\n","       l1_ratio=0.15, learning_rate='constant', loss='log', max_iter=None,\n","       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n","       power_t=0.5, random_state=15, shuffle=True, tol=0.001,\n","       validation_fraction=0.1, verbose=2, warm_start=False)"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"7WaVxhGpSvnj","colab_type":"code","outputId":"1e67badc-96e7-4633-eb72-1d4c24aaa295","colab":{}},"source":["clf.coef_, clf.coef_.shape, clf.intercept_"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([[-0.42328902,  0.18380407, -0.14437354,  0.34064016, -0.21316099,\n","          0.56702655, -0.44910569, -0.09094413,  0.21219292,  0.17750247,\n","          0.19931732, -0.00506998, -0.07781235,  0.33343476,  0.0320374 ]]),\n"," (1, 15),\n"," array([-0.85032916]))"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"markdown","metadata":{"id":"Su9e8fRLSvno","colab_type":"text"},"source":[" "]},{"cell_type":"markdown","metadata":{"id":"gcz5_UqCSvnq","colab_type":"text"},"source":[" "]},{"cell_type":"markdown","metadata":{"id":"UOBvEchCSvnr","colab_type":"text"},"source":["## Implement Logistc Regression with L2 regularization Using SGD: without using sklearn"]},{"cell_type":"markdown","metadata":{"id":"Xbn61rrXSvnt","colab_type":"text"},"source":["### Instructions"]},{"cell_type":"markdown","metadata":{"id":"14bA5yR3Svnv","colab_type":"text"},"source":["- Load the datasets(train and test) into the respective arrays"]},{"cell_type":"markdown","metadata":{"id":"c7183hFBSvnv","colab_type":"text"},"source":["- Initialize the weight_vector and intercept term randomly"]},{"cell_type":"markdown","metadata":{"id":"hdLeFU0USvnx","colab_type":"text"},"source":["- Calculate the initlal log loss for the train and test data with the current weight and intercept and store it in a list"]},{"cell_type":"markdown","metadata":{"id":"pEVtAlO1Svny","colab_type":"text"},"source":["- for each epoch:\n","    - for each batch of data points in train: (keep batch size=1)\n","        - calculate the gradient of loss function w.r.t each weight in weight vector\n","        - Calculate the gradient of the intercept <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>check this</a>\n","        - Update weights and intercept (check the equation number 32 in the above mentioned <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>pdf</a>): <br>\n","        $w^{(t+1)} ← (1 − \\frac{αλ}{N} )w^{(t)} + αx_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))$ <br>\n","        $b^{(t+1)} ← (1 − \\frac{αλ}{N} )b^{(t)} + α(y_n − σ((w^{(t)})^{T} x_n+b^{t}))$ \n","        - calculate the log loss for train and test with the updated weights (you can check the python assignment 10th question)\n","        - And if you wish, you can compare the previous loss and the current loss, if it is not updating, then\n","        you can stop the training\n","        - append this loss in the list ( this will be used to see how loss is changing for each epoch after the training is over )\n"]},{"cell_type":"markdown","metadata":{"id":"2qmRH4UpSvny","colab_type":"text"},"source":["- Plot the train and test loss i.e on x-axis the epoch number, and on y-axis the loss"]},{"cell_type":"markdown","metadata":{"id":"lbZf9p5gSvn1","colab_type":"text"},"source":["- <strong>GOAL</strong>: compare your implementation and SGDClassifier's the weights and intercept, make sure they are as close as possible i.e difference should be in terms of 10^-3"]},{"cell_type":"code","metadata":{"id":"Fpz8X5DMSvn2","colab_type":"code","colab":{}},"source":["w = np.zeros_like(X_train[0])\n","b = 0\n","eta0  = 0.0001\n","alpha = 0.0001\n","N = len(X_train)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"B6Y5kVscSvn5","colab_type":"code","colab":{}},"source":["# write your code to implement SGD as per the above instructions\n","# please choose the number of iternations on your own"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"Yy8jWaa7Svn_","colab_type":"code","outputId":"a5bdc6de-084e-4c0d-d905-3529d0dd268a","colab":{}},"source":["# these are the results we got after we implemented sgd and found the optimal weights and intercept\n","w-clf.coef_, b-clf.intercept_"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([[ 1.35902934e-04,  7.15571169e-03, -1.50763324e-03,\n","         -2.49025574e-03,  1.19476006e-03, -1.76677259e-03,\n","          3.72211992e-03, -7.72662199e-04,  5.76021912e-03,\n","         -7.72849240e-03, -4.09688016e-03,  7.36552525e-03,\n","         -2.25926280e-06,  5.39142249e-03, -9.89505797e-03]]),\n"," array([0.00023241]))"]},"metadata":{"tags":[]},"execution_count":60}]},{"cell_type":"code","metadata":{"id":"48gx6wQKSvoE","colab_type":"code","outputId":"73838465-1f8e-4697-fe22-c49a816e1207","colab":{}},"source":["def pred(w,b, X):\n","    N = len(X)\n","    predict = []\n","    for i in range(N):\n","        if sigmoid(w, X[i], b) >= 0.5: # sigmoid(w,x,b) returns 1/(1+exp(-(dot(x,w)+b)))\n","            predict.append(1)\n","        else:\n","            predict.append(0)\n","    return np.array(predict)\n","print(1-np.sum(y_train - pred(w,b,X_train))/len(X_train))\n","print(1-np.sum(y_test  - pred(w,b,X_test))/len(X_test))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0.95536\n","0.95296\n"],"name":"stdout"}]}]}